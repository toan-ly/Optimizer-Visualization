# Optimizer Visualization using MATLAB
## Overview
This project provides interactive visualizations to compare the convergence behavior of popular optimization algorithms that I implemented from scratch: 
* __Gradient Descent__
* __Gradient Descent with Momentum (Momentum)__
* __Nesterov Accelerated Gradient (NAG)__
* __Adaptive Gradient (AdaGrad)__
* __RMSProp__
* __AdaDelta__
* __Adam__
  
By observing the animations, you can gain valuable insights into how these algorithms navigate towards the global minimum of a cost function.

## Motivation
Understanding the behavior and performance of optimization algorithms is essential in various fields such as machine learning, optimization problems, and mathematical modeling. This project aims to provide a visual comparison of commonly used optimizers to aid in understanding their strengths and weaknesses.

## Requirements
* MATLAB

## Demo
